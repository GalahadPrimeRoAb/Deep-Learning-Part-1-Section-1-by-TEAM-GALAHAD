import requests
import csv
import re
from bs4 import BeautifulSoup

for count in range(4000):
    url = 'https://www.wikihow.com/Special:Randomizer'

    response = requests.get(url)
    html_content = response.content

    soup = BeautifulSoup(html_content, 'html.parser')
    article_title = soup.find('title').text.strip()
    print(article_title + str(count))

    subheadings = []
    paragraphs = []
    steps = soup.find_all('div', {'class': 'step'})
    for step in steps:
        subheading_element = step.find('b')
        if subheading_element is not None:
            subheading_text = subheading_element.text.strip().replace('\n', ' ')
            subheading_text = subheading_text.encode('ascii', errors='ignore').decode()
            subheading_text = re.sub(r'\s+', ' ', subheading_text)
            subheadings.append(subheading_text)

        paragraph_element = step.find('span')
        if paragraph_element is not None:
            paragraph_text = paragraph_element.text.strip().replace('\n', ' ').replace('  ', ' ')
            paragraph_text = paragraph_text.encode('ascii', errors='ignore').decode()
            paragraph_text = re.sub(r'\s+', ' ', paragraph_text)
            paragraphs.append(paragraph_text)

    # Write subheadings and paragraphs to the CSV file
    if len(subheadings) > 0:
        with open('/content/wikiHow.csv', mode='a', newline='', encoding='utf-8') as csv_file:
            writer = csv.writer(csv_file)
            for i in range(min(len(subheadings), len(paragraphs))):
                writer.writerow([article_title, subheadings[i], paragraphs[i]])
